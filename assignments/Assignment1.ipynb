{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formalia:\n",
    "\n",
    "Please read the [assignment overview page](https://github.com/lalessan/comsocsci2022/wiki/Assignments) carefully before proceeding. This page contains information about formatting (including formats etc), group sizes, and many other aspects of handing in the assignment. \n",
    "\n",
    "_If you fail to follow these simple instructions, it will negatively impact your grade!_\n",
    "\n",
    "**Due date and time**: The assignment is due on March 1st at 23:55. Hand in your Jupyter notebook file (with extension `.ipynb`) via DTU Learn _(Course Content, Assignemnts, Assignment 1)_. \n",
    "\n",
    "Remember to include in the first cell of your notebook:\n",
    "* the link to your group's Git repository\n",
    "* group members' contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Datasets for Computational Social Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ten characteristics of Big Data._ Consider the dataset you have collected in Week 1, and think of the *10 characteristics of Big Data* from the book [Bit by Bit section 2.3](https://www.bitbybitbook.com/en/1st-ed/observing-behavior/characteristics/).\n",
    "> * **Big**. How large is this data (approximately)? Could you collect the same amount of information via surveys?\n",
    "> * **Always-on**. Can you keep collecting data over time?\n",
    "> * **Non-reactive**. Is the dataset non-reactive?\n",
    "> * **Incomplete**. Do you think the dataset captures entirely the unfolding of events leading to the GME stock rise in price? \n",
    "> * **Inaccessible**. Is the data accessible? \n",
    "> * **Non-representative**. Do you think that the conclusions we will draw by analyzing this dataset are specific to the GME events? Or could they instead help us understand social phenomena more in general? If yes, which phenomena could you think of? Of not, what are the aspects that make this dataset non-representative?\n",
    "> * **Drifting**. Is there any source of *drift* in this dataset (within the period observed)? \n",
    "> * **Algorithmically confounded**. Is the dataset algorithmically confounded? If yes, why?\n",
    "> * **Dirty**. What aspect may make this dataset *dirty*?\n",
    "> * **Sensitive**. Is there any sensitive information in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: activity on Reddit and GME prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Consider the following datasets: \n",
    " * the *GME market data*, that you can download from [here](https://finance.yahoo.com/quote/GME/history/). \n",
    " * the dataset you downloaded in Week1, Exercise 2. We will refer to this as the _comments dataset_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Part 2.1 : Plotting prices and comments using line-graphs._\n",
    "> 1. Plot the daily volume of the GME stock over time using the _GME market data_. On top of the daily data, plot the rolling average, using a 7 days window (you can use the function [``pd.rolling``](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html)). Use a [log-scale on the y-axis](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.yscale.html).\n",
    "> 2. Now make a second plot where you plot the total number of comments on Reddit per day. Follow the same steps you followed in step 1.\n",
    "> 3. What is the advantage of using the log-scale on the y-axis? What is the advantage of using a rolling-window?\n",
    "> 3. Now take a minute to __look at these two figures__. Then write in a couple of lines: What are the three most important observations you can draw by looking at the figures?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> _Part 2.2: Returns vs number of comments using scatter-plots_.\n",
    "> In this part of the assignment, we will look at the association between GME market indicators and the volume of comments on Reddit. \n",
    "> 1. Compute the daily log-returns as ``np.log(Close_price(t)/Close_price(t-1))``, where ``Close_price(t)`` is the Close Price of GME on day t. You can use the function [pd.Series.shift](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.shift.html). Working with log-returns instead of regular returns is a standard thing to do in economics, if you are interested in why, check out [this blog post](https://quantivity.wordpress.com/2011/02/21/why-log-returns/).\n",
    "> 2. Compute the daily log-change in number of new comments as ``np.log(comments(t)/comments(t-1))`` where ``comments(t)`` is the number of comments on day t. \n",
    "> 3. Compute the correlation coefficient (find the formula in the Data Visualization book, section 12.2) between the series computed in step 1 and step 2 (note that you need to first remove days without any comments from the time-series). Is the correlation statistically significant? \n",
    "> 4. Make a [scatter plot](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html) of the daily log-return on investment for the GME stock against the daily log-change in number of comments. Color the markers for 2020 and 2021 in different colors, and make the marker size proportional to the Close price. \n",
    "> 5. Now take a minute to __look at the figure you just prepared__. Then write in a couple of lines: What are the three most salient observations you can draw by looking at it? \n",
    "> 6. Based on the exploratory data visualization in Exercises 2 and 3, what can you conclude on the research question: *Is the activity on wallstreetbet related to the price of the GME stock?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part 3: Exercises using the `NetworkX` library\n",
    "\n",
    "> Solve the following exercises from your [Network Science book](http://networksciencebook.com).\n",
    "> * Go to Section 2.12: [Homework](http://networksciencebook.com/chapter/2#homework2), then\n",
    ">     * Write the solution for exercise 2.1 (the 'KÃ¶nigsberg Problem') from NS in your notebook.\n",
    ">     * Solve exercise 2.3 ('Graph representation') from NS using NetworkX in your notebook. (You don't have to solve the last sub-question about cycles of length 4).\n",
    ">     * Solve exercise 2.5 ('Bipartite Networks') from NS using NetworkX in your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Properties of the real-world network of Redditors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the assignment, consider the directed network of redditors posting about GME on r/wallstreetbets in the period included between Jan 1st and Dec 31st, 2020 (the one you built in Week 3, Part 3).\n",
    "\n",
    "> _Part 4.1 Random Network_: Create a Random Network as a null model to investigate some properties of the Redditors Network.\n",
    "> * Compute the value of _p_ such that the number of expected edges of the random network equals the number of edges in the redditor network (see equation 3.2 in your Network Science Book). What is the value of p? Compute the average value of the degree < k > (using the formula).\n",
    "> * Create a Random network with the same number of nodes as the redditor networks, and _p_ as computed above. Generate a random network by linking nodes in every possible pair with probability _p_.\n",
    "> * Visualize the Redditors Network and the Random Network. Comment on the differences between the two.\n",
    ">\n",
    "> _Part 4.2 Clustering_: Compare the clustering coefficient in the Redditors Network and its random counterpart.\n",
    "> * Compute the clustering coefficient for all nodes in the random network, using the formula 2.15 in your book.  \n",
    "> * Compute the average clustering across nodes of the random network. Is it consistent with the analytical prediction (network science book equation 3.21)?\n",
    "> * Compute the average clustering coefficient for the Redditors network. How does it compare to its random counterpart? Is it something you would expect? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
